#This file contains the individual functions used in decisionTree.py.
#All code was written by John Phillips

import os

#This function verifies that the file exists and then returns the relative path
def loadFile(purpose="train"):
    flag = False
    check = input("Please enter your {}ing data:".format(purpose))
    path = "./{}".format(check)
    if not (os.path.isfile('{}'.format(path))):
        flag = True
    while flag == True:
        check = input("The file wasn't found. Please enter your {}ing data:".format(purpose))
        path = "./{}".format(check)
        if (os.path.isfile('{}'.format(path))):
            flag = False
    return path

#This function ensures that the training and testing data match in terms of
#attributes
def verifyData(trainPath, testPath):
    flag = False

    trainAttributes, trainData = loadData(trainPath)
    testAttributes, testData = loadData(testPath)

    if(len(trainAttributes) == len(testAttributes)):
        i = 0
        for attribute in trainAttributes:
            if(trainAttributes[i] != testAttributes[i]):
                flag = True
            i += 1

    if(flag==True):
        return [], []
    else:
        return trainData, testData, flag

#This function reads the data file into a data structure and returns the first
#row as well as the whole of the data
def loadData(filepath):
    fileReader = open(filepath, "r")
    rawData = []
    for row in fileReader:
        values = row.split()
        if(values):
            rawData.append(values)

    #The attributes are in the first line of the data file, so grab them
    attributes = rawData[0]
    return attributes, rawData


#Make a dictionary that keeps track of which attribute each value belongs to
def identifyAttributes(dataset):
    dictValToAtt = {}
    headers = dataset[0]
    itemNum = 0
    labels = []

    for row in dataset[1:]:
        for value in row:
            #If it's not in the dictionary, add it
            if value not in dictValToAtt.keys():
                dictValToAtt["{}".format(value)] = headers[itemNum]
                if itemNum == len(row)-1:
                    labels.append(value)
            itemNum += 1
        itemNum = 0

    return dictValToAtt, labels

def train(dataset, target, dictValToAtt):
    #Step 1: calculate the prior probabilities for different values of the
    #       target attribute.
    totalRows = len(dataset)
    headers = dataset[0]
    targetValues = []
    nonTargetValues = []

    #find all the possible values for the target attribute
    for key, value in dictValToAtt.items():
        if value == headers[target]:
            targetValues.append(key)

    #start a value counting dictionary for target values, initialize to 0
    targetValueDict = {}
    for entry in targetValues:
        targetValueDict['{}'.format(entry)] = 0

    #count occurrences of each value in the training dataset
    for row in dataset[1:]:
        targetValueDict['{}'.format(row[target])] += 1

    #Step 2: calculate all prior probabilities for values of other attributes
    #       based on subsets generated by target attributes.
    # probDict = {}
    # probTargetPriorDict = {}
    #
    # for attribute in headers:
    #     for entry in targetValues:
    #         for row in dataset[1:]:
    #             if row[target] == entry:

    return targetValueDict


#Format the results and write them to a file Results.txt
def generateResults(testData, target, targetDict, labels):
    results = open("Results.txt", "w")
    flag = True
    headers = testData[0]

    correctCount = 0
    totalCount = len(testData)-1

    for row in testData:
        if not flag:
            rowTarget = row[int(target)-1]

            for item in row:
                results.write("{}\t".format(item))

            if targetDict['{}'.format(rowTarget)] == max(targetDict.values()):
                if row[len(headers)-1] == 'p':
                    correctCount += 1
                results.write("p\n")

            else:
                if row[len(headers)-1] == 'n':
                    correctCount += 1
                results.write("n\n")
        else:
            for item in row:
                results.write("{0}\t".format(item))
            results.write("Classification\n")
            flag = False

    results.write("\nAccuracy: {0}/{1}".format(correctCount, totalCount))
